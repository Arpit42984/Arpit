{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "id": "rb68NkUaZovM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import load_model,Model\n",
        "from sklearn.metrics import classification_report\n",
        "import tenseal as ts\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "zg08fD9D1_ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load AG News dataset\n",
        "dataset = load_dataset('ag_news')\n",
        "\n",
        "# Split into train and test sets\n",
        "train_texts = dataset['train']['text']\n",
        "train_labels = dataset['train']['label']\n",
        "test_texts = dataset['test']['text']\n",
        "test_labels = dataset['test']['label']\n",
        "\n",
        "\n",
        "# Subset the dataset (similar to image classification approach)\n",
        "def subset_data(texts, labels, num_classes=4, samples_per_class=1000):\n",
        "    selected_texts = []\n",
        "    selected_labels = []\n",
        "\n",
        "    for label in range(num_classes):\n",
        "        indices = np.where(np.array(labels) == label)[0]\n",
        "        selected_indices = indices[:samples_per_class]  # Select first N samples per class\n",
        "        selected_texts.extend(np.array(texts)[selected_indices])\n",
        "        selected_labels.extend(np.array(labels)[selected_indices])\n",
        "\n",
        "    # Shuffle the texts and labels together to maintain the mapping\n",
        "    selected_texts, selected_labels = shuffle(selected_texts, selected_labels, random_state=42)\n",
        "\n",
        "    return selected_texts, selected_labels\n",
        "\n",
        "\n",
        "# Extract subsets (1000 samples per class)\n",
        "train_texts, train_label = subset_data(train_texts, train_labels, num_classes=4, samples_per_class=1000)\n",
        "\n",
        "# 3. Preprocess the data (Tokenization and padding)\n",
        "vocab_size = 10000  # Limit vocabulary size\n",
        "max_length = 100  # Limit the length of input sequences\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "# Convert texts to sequences of integers\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Convert labels to TensorFlow format\n",
        "train_labels = np.array(train_label)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels = to_categorical(train_labels, num_classes=4)\n",
        "test_labels = to_categorical(test_labels, num_classes=4)\n",
        "\n",
        "# 4. Function to build the model\n",
        "def define_text_classification_model():\n",
        "    input_layer = Input(shape=(max_length,), name='input')\n",
        "\n",
        "    # Embedding layer\n",
        "    embedding_layer = Embedding(vocab_size, 64, input_length=max_length, name='embedding')(input_layer)\n",
        "\n",
        "    # Global average pooling layer\n",
        "    pooling_layer = GlobalAveragePooling1D(name='global_avg_pooling')(embedding_layer)\n",
        "\n",
        "    # Hidden Dense layer\n",
        "    hidden_layer = Dense(64, activation='relu', name='hidden_dense')(pooling_layer)\n",
        "\n",
        "    # Output logits layer (without softmax)\n",
        "    logits_layer = Dense(4, name='logits')(hidden_layer)\n",
        "\n",
        "    # Define the model (excluding softmax)\n",
        "    model = Model(inputs=input_layer, outputs=logits_layer)\n",
        "\n",
        "    # Compile the model (from_logits=True because we didn't apply softmax)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 5. Save initial weights\n",
        "initial_model = define_text_classification_model()\n",
        "initial_weights = initial_model.get_weights()\n",
        "\n",
        "# Function to create a new model with the same initial weights\n",
        "def create_model_with_initial_weights():\n",
        "    model = define_text_classification_model()\n",
        "    model.set_weights(initial_weights)\n",
        "    return model\n",
        "\n",
        "# 6. Run the test harness with subset data\n",
        "def run_text_classification_test_harness():\n",
        "    # Create new model instance\n",
        "    model = create_model_with_initial_weights()\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(train_padded, train_labels, epochs=20,\n",
        "                        validation_data=(test_padded, test_labels), batch_size=64)\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, accuracy = model.evaluate(test_padded, test_labels, verbose=0)\n",
        "    print(f\"> Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Save the model\n",
        "    model.save('text_classification_model.keras')\n",
        "\n",
        "# 7. Run the test harness\n",
        "run_text_classification_test_harness()\n",
        "\n",
        "# 8. Predict sample text (without softmax in the model)\n",
        "sample_texts = [\"The stock market is volatile.\"]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_texts)\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Load model and make predictions\n",
        "loaded_model = tf.keras.models.load_model('text_classification_model.keras')\n",
        "\n",
        "# Get logits\n",
        "logits = loaded_model.predict(sample_padded)\n",
        "\n",
        "# Apply softmax manually to get probabilities\n",
        "softmax_output = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "# Get predicted class\n",
        "predicted_class = tf.argmax(softmax_output, axis=-1).numpy()[0]\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "QkWGy8ClZwzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "GKS46-sx2AnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subset_ag_news(args, num_classes=4):\n",
        "    if len(args) != num_classes:\n",
        "        raise ValueError(f\"Exactly {num_classes} integer arguments are required for the first {num_classes} classes.\")\n",
        "\n",
        "    # Load AG News dataset\n",
        "    dataset = load_dataset('ag_news')\n",
        "\n",
        "    # Extract texts and labels\n",
        "    train_texts = dataset['train']['text']\n",
        "    train_labels = dataset['train']['label']\n",
        "\n",
        "    # Shuffle the dataset before selecting a subset\n",
        "    train_texts, train_labels = shuffle(train_texts, train_labels)\n",
        "\n",
        "    selected_texts = []\n",
        "    selected_labels = []\n",
        "\n",
        "    # Select the subset of samples for the first `num_classes` classes\n",
        "    for label in range(num_classes):\n",
        "        # Get indices of the current label\n",
        "        indices = np.where(np.array(train_labels) == label)[0]\n",
        "        num_samples = args[label]\n",
        "\n",
        "        if num_samples > len(indices):\n",
        "            raise ValueError(f\"Requested {num_samples} samples for class {label}, but there are only {len(indices)} samples available.\")\n",
        "\n",
        "        # Select the specified number of samples for this class\n",
        "        selected_indices = indices[:num_samples]\n",
        "        selected_texts.extend(np.array(train_texts)[selected_indices])\n",
        "        selected_labels.extend(np.array(train_labels)[selected_indices])\n",
        "\n",
        "    # Shuffle the selected texts and labels together to maintain the mapping\n",
        "    selected_texts, selected_labels = shuffle(selected_texts, selected_labels, random_state=42)\n",
        "\n",
        "    return selected_texts, selected_labels\n",
        "\n",
        "\n",
        "def feature_extractor(texts, model = loaded_model):\n",
        "    # Preprocess the texts (tokenization and padding)\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "    # Get feature vectors from the model\n",
        "    feature_vectors = model.predict(padded_sequences, verbose=0)\n",
        "\n",
        "    # Normalize the feature vectors\n",
        "    row_norms = np.linalg.norm(feature_vectors, axis=1, keepdims=True)\n",
        "    normalized_feature_vectors = feature_vectors / row_norms\n",
        "\n",
        "    return normalized_feature_vectors"
      ],
      "metadata": {
        "id": "GCZn8U5QaDJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_zeros(number):\n",
        "    if number <= 0 or number >= 1:\n",
        "        raise ValueError(\"Number should be between 0 and 1, exclusive.\")\n",
        "\n",
        "    count = 0\n",
        "    while number < 1:\n",
        "        number *= 10\n",
        "        count += 1\n",
        "        if number >= 1:\n",
        "            break\n",
        "\n",
        "    return count - 1\n",
        "\n",
        "# Base under-sampling method for text classification\n",
        "def base_under_sampling(texts, labels, LD):\n",
        "    LI = min(LD) / max(LD)\n",
        "    if LI >= 0.05:\n",
        "        print(\"Client already balanced\")\n",
        "        return texts, labels, LD\n",
        "\n",
        "    x_train = np.array(texts)\n",
        "    y_train = np.array(labels)\n",
        "    distr = LD\n",
        "\n",
        "    while LI < 0.05:\n",
        "        selected_class = np.argmax(distr)\n",
        "        num = count_zeros(LI)\n",
        "\n",
        "        # Get indices of the most over-represented class\n",
        "        class_indices = np.where(y_train == selected_class)[0]\n",
        "        class_texts = x_train[class_indices]\n",
        "\n",
        "        # Extract feature vectors for the class (embeddings from the model)\n",
        "        feature_vectors = feature_extractor(class_texts)\n",
        "\n",
        "        # Compute cosine similarity matrix\n",
        "        cosine_sim_matrix = cosine_similarity(feature_vectors)\n",
        "        n = cosine_sim_matrix.shape[0]\n",
        "        print(n)\n",
        "\n",
        "        # Compute mean and variance for each row in the similarity matrix\n",
        "        row_means = np.mean(cosine_sim_matrix, axis=1)\n",
        "        row_variances = np.var(cosine_sim_matrix, axis=1)\n",
        "\n",
        "        # Sort rows based on mean values in descending order\n",
        "        sorted_indices = np.argsort(row_means)[::-1]\n",
        "        print(num + 1)\n",
        "\n",
        "        # Select the top rows with the highest mean values\n",
        "        selected_indices = sorted_indices[:int((10 ** (num + 1)) / 5)]\n",
        "\n",
        "        # Calculate variance of the selected rows\n",
        "        selected_var = np.var(cosine_sim_matrix[selected_indices], axis=0)\n",
        "\n",
        "        # Iterate through remaining rows and add rows to minimize variance\n",
        "        for i in sorted_indices[int((10 ** (num + 1)) / 5):]:\n",
        "            temp_indices = np.append(selected_indices, i)\n",
        "            temp_var = np.var(cosine_sim_matrix[temp_indices], axis=0)\n",
        "            if np.sum(temp_var) < np.sum(selected_var):\n",
        "                selected_var = temp_var\n",
        "                selected_indices = temp_indices\n",
        "            if len(selected_indices) == int((10 ** (num + 1)) / 5):\n",
        "                break\n",
        "\n",
        "        print(f\"Texts to be removed: {len(selected_indices)} from class {selected_class}\")\n",
        "\n",
        "        # Translate selected indices to the original dataset\n",
        "        remove_indices = class_indices[selected_indices]\n",
        "\n",
        "        # Remove selected samples\n",
        "        mask = np.ones(len(y_train), dtype=bool)\n",
        "        mask[remove_indices] = False\n",
        "        x_train = x_train[mask]\n",
        "        y_train = y_train[mask]\n",
        "\n",
        "        # Update the class distribution\n",
        "        new_distr = np.copy(distr)\n",
        "        new_distr[selected_class] -= len(remove_indices)\n",
        "        distr = new_distr\n",
        "        LI = min(distr) / max(distr)\n",
        "        print(LI)\n",
        "\n",
        "    return x_train, y_train, distr"
      ],
      "metadata": {
        "id": "2I-mXsmtaIOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def over_sampling_from_folder_client(texts, labels, LD, min_imbalance=0.05):\n",
        "    LI = min(LD) / max(LD)\n",
        "    print(f\"Initial imbalance ratio: {LI}\")\n",
        "    if LI >= min_imbalance:\n",
        "        print(\"Class imbalance is already below the threshold\")\n",
        "        return texts, labels, LD\n",
        "\n",
        "    # Vectorize the texts\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Track original labels to preserve order\n",
        "    original_label_count = len(labels)\n",
        "    ts_total = min(LD)\n",
        "    while LI < min_imbalance:\n",
        "        # Identify the minority class\n",
        "        minority_class = np.argmin(LD)\n",
        "        # Use a dictionary for sampling_strategy to target the minority class\n",
        "        target_samples = int((1 / LI) + ts_total)\n",
        "        print(target_samples)\n",
        "        ts_total += target_samples\n",
        "        max_samples = int(max(LD) * 0.5)  # Adjust this value as needed\n",
        "        print(max_samples)\n",
        "        sampling_strategy = {minority_class : min(target_samples, max_samples)}\n",
        "        smote = SMOTE(sampling_strategy=sampling_strategy)\n",
        "\n",
        "        # Apply SMOTE and resample both features (X) and labels (y)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "        # Only keep the newly added samples\n",
        "        new_samples = len(y_resampled) - len(labels)\n",
        "        new_X_resampled = X_resampled[-new_samples:]\n",
        "        new_y_resampled = y_resampled[-new_samples:]\n",
        "\n",
        "        # Reconstruct text data from augmented features\n",
        "        augmented_texts = vectorizer.inverse_transform(new_X_resampled)\n",
        "\n",
        "        # Update texts and labels with only the newly created data\n",
        "        texts.extend([' '.join(text) for text in augmented_texts])  # Reconstruct text from features\n",
        "        labels.extend(new_y_resampled)\n",
        "\n",
        "        # Re-vectorize to ensure texts and labels stay in sync\n",
        "        X = vectorizer.fit_transform(texts)\n",
        "\n",
        "        # Recalculate class distribution\n",
        "        distr = np.bincount(labels, minlength=len(set(labels)))\n",
        "        LI = min(distr) / max(distr)\n",
        "        print(f\"Updated imbalance ratio: {LI}\")\n",
        "\n",
        "    return texts, labels, distr\n"
      ],
      "metadata": {
        "id": "nESEwwIhaM3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Server:\n",
        "    _instance = None  # Class variable to store the single instance\n",
        "\n",
        "    def __new__(cls, *args, **kwargs):\n",
        "        if not cls._instance:\n",
        "            cls._instance = super().__new__(cls, *args, **kwargs)\n",
        "            # Generate CKKS keys upon instantiation\n",
        "            cls._instance.__context = ts.context(\n",
        "                ts.SCHEME_TYPE.CKKS,\n",
        "                poly_modulus_degree=8192,\n",
        "                coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        "            )\n",
        "            cls._instance.__context.generate_galois_keys()\n",
        "            cls._instance.__context.global_scale = 2**40\n",
        "            cls._instance.__public_key = cls._instance.__context.public_key()\n",
        "            cls._instance.__relin_keys = cls._instance.__context.relin_keys()\n",
        "            cls._instance.__total_distr = None\n",
        "            cls._instance.enc_norm_distr = None\n",
        "            cls._instance.clients = []\n",
        "        return cls._instance\n",
        "\n",
        "    def encrypt_with_public_key(self, data):\n",
        "        \"\"\"Encrypt a vector of data using the public key.\"\"\"\n",
        "        return ts.ckks_vector(self.__context, data)\n",
        "\n",
        "    def decryption(self):\n",
        "        return Client.cumulative_encrypted_distribution.decrypt()\n",
        "\n",
        "    def decrypt(self, encrypted_data):\n",
        "        \"\"\"Decrypt the encrypted data.\"\"\"\n",
        "        return encrypted_data.decrypt()\n",
        "\n",
        "    def global_imbalance(self):\n",
        "        \"\"\"Calculate the global imbalance in class distributions across clients.\"\"\"\n",
        "        total_distr = [round(x) for x in self.__total_distr]\n",
        "        return min(total_distr) / max(total_distr)\n",
        "\n",
        "    def norm_enc(self):\n",
        "        \"\"\"Normalize the class distribution and return the encrypted normalized vector.\"\"\"\n",
        "        total_distr = [round(x) for x in self.__total_distr]\n",
        "        total_distribution = np.linalg.norm(total_distr)\n",
        "        normalized_distr = [x / total_distribution for x in total_distr]\n",
        "        return ts.ckks_vector(self.__context, normalized_distr)\n",
        "\n",
        "    def add_client(self, client):\n",
        "        \"\"\"Add a client to the server's list.\"\"\"\n",
        "        self.clients.append(client)\n",
        "\n",
        "    def cos_sim(self):\n",
        "        \"\"\"Compute cosine similarity between the server's global distribution and each client's distribution.\"\"\"\n",
        "        data = []\n",
        "        client_similarities = np.array(data)\n",
        "        self.enc_norm_distr = self.norm_enc()\n",
        "        for client in self.clients:\n",
        "            temp = client.cos_sim_calc(self.enc_norm_distr)  # Call client's cosine similarity function\n",
        "            temp_decrypt = temp.decrypt()  # Decrypt the result\n",
        "            client_similarities = np.append(client_similarities, temp_decrypt)\n",
        "        return client_similarities\n",
        "\n",
        "    def similarity_comparison(self, enc_selected_vectors, calling_client):\n",
        "        \"\"\"Compare encrypted vectors between clients.\"\"\"\n",
        "        results = []\n",
        "        for client in self.clients:\n",
        "            if client != calling_client:\n",
        "                result = client.plain_enc_mul(enc_selected_vectors)\n",
        "                results.append(result)\n",
        "        return results\n",
        "\n",
        "    def balance_check(self):\n",
        "        \"\"\"Main function to balance the class distribution across clients.\"\"\"\n",
        "        self.__total_distr = self.decryption()  # Get class distribution\n",
        "        print(\"Initial Distribution: \", self.__total_distr)\n",
        "\n",
        "        global_imbalance = self.global_imbalance()\n",
        "        print(\"Initial Imbalance: \", global_imbalance)\n",
        "\n",
        "        global_similarity_cl = self.cos_sim()\n",
        "        print(\"Initial Global Similarity: \", global_similarity_cl)\n",
        "\n",
        "        k = 1\n",
        "        GI_flag1, GI_flag2 = 0, 0\n",
        "        sorted_indices = np.argsort(global_similarity_cl)\n",
        "        rounds = 0\n",
        "\n",
        "        while global_imbalance < 0.1:\n",
        "            selected_client_index = sorted_indices[-k]\n",
        "            selected_client = self.clients[selected_client_index]\n",
        "            print(\"Selected client: \", selected_client_index)\n",
        "\n",
        "            enc_results = selected_client.trigger(GI_flag1, GI_flag2, 0)\n",
        "            if enc_results == 0:\n",
        "                k = k + 1\n",
        "                if k == 5:  # Handle wrap-around\n",
        "                    k = 1\n",
        "                    sorted_indices = np.argsort(global_similarity_cl)\n",
        "                    selected_client_index = sorted_indices[-k]\n",
        "                    selected_client = self.clients[selected_client_index]\n",
        "                    if(selected_client.trigger(GI_flag1,GI_flag2, 0) == 0):\n",
        "                        print(\"That's the best balance you can get\")\n",
        "                        print(\"number of rounds  : \", round)\n",
        "                        break\n",
        "                GI_flag1, GI_flag2 = 0, 0\n",
        "                continue\n",
        "\n",
        "            prev_global_imbalance = global_imbalance\n",
        "            self.__total_distr = enc_results.decrypt()\n",
        "            global_imbalance = self.global_imbalance()\n",
        "            global_similarity_cl = self.cos_sim()\n",
        "\n",
        "            print(\"Global Imbalance: \", global_imbalance)\n",
        "            print(\"Global Similarities: \", global_similarity_cl)\n",
        "\n",
        "            if prev_global_imbalance >= global_imbalance:\n",
        "                GI_flag1 = 1\n",
        "\n",
        "            enc_results = selected_client.trigger(GI_flag1, GI_flag2, 1)\n",
        "            if enc_results == 0:\n",
        "                k += 1\n",
        "                if k == 5:\n",
        "                    k = 1\n",
        "                    sorted_indices = np.argsort(global_similarity_cl)\n",
        "                    selected_client_index = sorted_indices[-k]\n",
        "                    selected_client = self.clients[selected_client_index]\n",
        "                    if(selected_client.trigger(GI_flag1,GI_flag2, 0) == 0):\n",
        "                        print(\"That's the best balance you can get\")\n",
        "                        print(\"number of rounds  : \", round)\n",
        "                        break\n",
        "                GI_flag1, GI_flag2 = 0, 0\n",
        "                continue\n",
        "\n",
        "            prev_global_imbalance = global_imbalance\n",
        "            self.__total_distr = enc_results.decrypt()\n",
        "            global_imbalance = self.global_imbalance()\n",
        "            global_similarity_cl = self.cos_sim()\n",
        "\n",
        "            print(\"Updated Global Imbalance: \", global_imbalance)\n",
        "            print(\"Updated Global Similarities: \", global_similarity_cl)\n",
        "\n",
        "            if prev_global_imbalance >= global_imbalance:\n",
        "                GI_flag2 = 1\n",
        "\n",
        "            rounds += 1\n",
        "\n",
        "        print(\"Balancing completed in rounds: \", rounds)\n",
        "        return 0"
      ],
      "metadata": {
        "id": "lWSnh4jGaWNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class Client:\n",
        "    cumulative_encrypted_distribution = None  # Class variable to store cumulative encrypted distribution\n",
        "\n",
        "    def __init__(self, distr, server, client_id):\n",
        "        if len(distr) != 4:\n",
        "            raise ValueError(\"class_samples must be a list or array of four integers.\")\n",
        "\n",
        "        self.context = ts.context(\n",
        "            ts.SCHEME_TYPE.CKKS,\n",
        "            poly_modulus_degree=8192,\n",
        "            coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        "        )\n",
        "        self.context.generate_galois_keys()\n",
        "        self.context.global_scale = 2**40\n",
        "\n",
        "        self.__distr = distr  # Private attribute\n",
        "        self.__dataset = self.__allocate_dataset(distr)  # Allocate and store the dataset\n",
        "        self.__feature_vectors = feature_extractor(self.__dataset[0])  # Assuming the dataset has text data\n",
        "        self.__imbalance = min(self.__distr) / max(self.__distr)\n",
        "        self.client_id = client_id\n",
        "        self.server = server\n",
        "        self._method_called = False\n",
        "        self.i = None\n",
        "        self.j = None\n",
        "        self.server.add_client(self)\n",
        "        self.__update_cumulative_distribution()\n",
        "\n",
        "    def __allocate_dataset(self, distr):\n",
        "        return subset_ag_news(distr)  # Implement this function to allocate text data\n",
        "\n",
        "    def cos_sim_calc(self, enc_distr):\n",
        "        total = np.linalg.norm(self.__distr)\n",
        "        norm_distr = [x/total for x in self.__distr]\n",
        "        vec = enc_distr.mul(norm_distr)\n",
        "        return vec.sum()\n",
        "\n",
        "    def encrypt_server_pub_key(self):\n",
        "        total_distribution = sum(self.__distr)\n",
        "        normalized_distr = [x/total_distribution for x in self.__distr]\n",
        "        return self.server.encrypt_with_public_key(self.__distr), self.server.encrypt_with_public_key(normalized_distr)\n",
        "\n",
        "    def use_dataset(self):\n",
        "        x_subset, y_subset = self.__dataset\n",
        "        print(\"Dataset Shape:\", len(x_subset), len(y_subset))\n",
        "        print(\"Feature vector:\", self.__feature_vectors.shape)\n",
        "        return x_subset, y_subset, self.__distr\n",
        "\n",
        "    def __update_cumulative_distribution(self):\n",
        "        if Client.cumulative_encrypted_distribution is None:\n",
        "            encrypted_distribution, _ = self.encrypt_server_pub_key()\n",
        "            Client.cumulative_encrypted_distribution = encrypted_distribution\n",
        "        else:\n",
        "            Client.cumulative_encrypted_distribution = Client.cumulative_encrypted_distribution.add_(self.__distr)\n",
        "\n",
        "    def plain_enc_mul(self, enc_vector):\n",
        "        plain_matrix = np.array(self.__feature_vectors)\n",
        "        plain_matrix = np.transpose(plain_matrix)\n",
        "        results = []\n",
        "        for i in range(math.ceil(plain_matrix.shape[1] / 3000)):\n",
        "            result = enc_vector.matmul(plain_matrix[:, (i * 3000):min(((i + 1) * 3000), plain_matrix.shape[1])])\n",
        "            results.append(result)\n",
        "        return results\n",
        "\n",
        "    def under_sampling(self, selected_class, feature_vectors):\n",
        "        cosine_sim_matrix = cosine_similarity(feature_vectors)\n",
        "        n = cosine_sim_matrix.shape[0]\n",
        "        print(n)\n",
        "\n",
        "        # Compute the mean and variance for each row\n",
        "        row_means = np.mean(cosine_sim_matrix, axis=1)\n",
        "        row_variances = np.var(cosine_sim_matrix, axis=1)\n",
        "        # Sort the rows based on mean values in descending order\n",
        "        sorted_indices = np.argsort(row_means)[::-1]\n",
        "\n",
        "        # Select the top 1/10 of the rows with the highest mean values\n",
        "        selected_indices = sorted_indices[:int(n/15)]\n",
        "\n",
        "        # Calculate the variance of the selected rows\n",
        "        selected_var = np.var(cosine_sim_matrix[selected_indices], axis=0)\n",
        "\n",
        "        # Iterate through the remaining rows and select additional rows one by one\n",
        "        for i in sorted_indices[int(n/15):]:\n",
        "            temp_indices = np.append(selected_indices, i)\n",
        "            temp_var = np.var(cosine_sim_matrix[temp_indices], axis=0)\n",
        "            # If variance is lower, add the row to the selection\n",
        "            if np.sum(temp_var) < np.sum(selected_var):\n",
        "                selected_var = temp_var\n",
        "                selected_indices = temp_indices\n",
        "            # Break if the desired number of rows is reached\n",
        "            if len(selected_indices) == int(n/15):\n",
        "                break\n",
        "        print(\"Samples selected : \",len(selected_indices))\n",
        "        samples_to_remove = []\n",
        "        # Return the indices of the selected rows\n",
        "        data =[]\n",
        "        for i in selected_indices:\n",
        "            similarities = np.array(data)\n",
        "            enc_sim_1, enc_sim_2, enc_sim_3 = server.similarity_comparison(ts.ckks_vector(self.context,feature_vectors[i]),self)\n",
        "            for j in range(len(enc_sim_1)):\n",
        "                temp = enc_sim_1[j].decrypt()\n",
        "                similarities = np.concatenate((similarities,temp))\n",
        "            for j in range(len(enc_sim_2)):\n",
        "                temp = enc_sim_2[j].decrypt()\n",
        "                similarities = np.concatenate((similarities,temp))\n",
        "            for j in range(len(enc_sim_3)):\n",
        "                temp = enc_sim_3[j].decrypt()\n",
        "                similarities = np.concatenate((similarities,temp))\n",
        "            c = np.sum(similarities > 0.98)\n",
        "            if(c >= 300):\n",
        "                samples_to_remove.append(i)\n",
        "        print(\"images to be removed : \",len(samples_to_remove),\" of class \",(selected_class))\n",
        "        # Convert lists to numpy arrays for easy indexing\n",
        "        X_train = np.array(self.__dataset[0])\n",
        "        Y_train = np.array(self.__dataset[1])\n",
        "        f_vectors = np.array(self.__feature_vectors)\n",
        "\n",
        "        # Get indices of the samples belonging to the selected class\n",
        "        selected_class_indices = np.where(Y_train == selected_class)[0]\n",
        "\n",
        "        # Translate samples_to_remove indices to indices in the original dataset\n",
        "        remove_indices = selected_class_indices[samples_to_remove]\n",
        "\n",
        "        # Create masks for removing samples\n",
        "        mask = np.ones(len(Y_train), dtype=bool)\n",
        "        mask[remove_indices] = False\n",
        "\n",
        "        # Apply masks to x_train and y_train to remove selected samples\n",
        "        X_train = X_train[mask]\n",
        "        Y_train = Y_train[mask]\n",
        "        f_vectors = f_vectors[mask]\n",
        "        Client.cumulative_encrypted_distribution = Client.cumulative_encrypted_distribution.sub_(self.__distr)\n",
        "        # Update the class distribution\n",
        "        new_distr = np.copy(self.__distr)\n",
        "        new_distr[selected_class] -= len(remove_indices)\n",
        "        self.__distr = new_distr\n",
        "        my_list = list(self.__dataset)\n",
        "        my_list[0] = X_train\n",
        "        my_list[1] = Y_train\n",
        "        self.__dataset = tuple(my_list)\n",
        "        self.__feature_vectors = f_vectors\n",
        "        Client.cumulative_encrypted_distribution = Client.cumulative_encrypted_distribution.add_(self.__distr)\n",
        "        return 0\n",
        "\n",
        "\n",
        "    def over_sampling_from_folder_client(self, min_imbalance = 0.05):\n",
        "        LD = self.__distr\n",
        "        print(LD)\n",
        "        LI = min(LD) / max(LD)\n",
        "        print(f\"Initial imbalance ratio: {LI}\")\n",
        "        if LI >= min_imbalance:\n",
        "            print(\"Class imbalance is already below the threshold\")\n",
        "            return texts, labels, LD\n",
        "        texts = list(self.__dataset[0])\n",
        "        labels = self.__dataset[1]\n",
        "        # Vectorize the texts\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        X = vectorizer.fit_transform(texts)\n",
        "\n",
        "        # Track original labels to preserve order\n",
        "        original_label_count = len(labels)\n",
        "        # Identify the minority class\n",
        "        minority_class = np.argmin(LD)\n",
        "        # Use a dictionary for sampling_strategy to target the minority class\n",
        "        target_samples = int((1 / LI) + LD[minority_class])\n",
        "        print(target_samples)\n",
        "        sampling_strategy = {minority_class : target_samples}\n",
        "        smote = SMOTE(sampling_strategy=sampling_strategy)\n",
        "        # Apply SMOTE and resample both features (X) and labels (y)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "        # Only keep the newly added samples\n",
        "        new_samples = len(y_resampled) - len(labels)\n",
        "        new_X_resampled = X_resampled[-new_samples:]\n",
        "        new_y_resampled = y_resampled[-new_samples:]\n",
        "\n",
        "        # Reconstruct text data from augmented features\n",
        "        augmented_texts = vectorizer.inverse_transform(new_X_resampled)\n",
        "\n",
        "        # Update texts and labels with only the newly created data\n",
        "        texts.extend([' '.join(text) for text in augmented_texts])  # Reconstruct text from features\n",
        "        labels = np.concatenate((labels, new_y_resampled))\n",
        "        print(new_samples,\" : samples added successfully in class\",minority_class)\n",
        "        # Re-vectorize to ensure texts and labels stay in sync\n",
        "        X = vectorizer.fit_transform(texts)\n",
        "\n",
        "        # Recalculate class distribution\n",
        "        distr = np.bincount(labels, minlength=len(set(labels)))\n",
        "        print(f\"Updated imbalance ratio: {LI}\")\n",
        "        self.__distr = distr\n",
        "        my_list = list(self.__dataset)\n",
        "        my_list[0] = texts\n",
        "        my_list[1] = labels\n",
        "        self.__dataset = tuple(my_list)\n",
        "        self.__feature_vectors = feature_extractor(texts)\n",
        "        Client.cumulative_encrypted_distribution = Client.cumulative_encrypted_distribution.add_(self.__distr)\n",
        "        return 0\n",
        "\n",
        "\n",
        "    def trigger(self, GI_flag1, GI_flag2, sampling):\n",
        "        self.__imbalance = min(self.__distr) / max(self.__distr)\n",
        "        print(self.__imbalance)\n",
        "        if self.__imbalance >= 0.05:\n",
        "            print(\"Client \", self.client_id, \" is already balanced\")\n",
        "            return 0\n",
        "\n",
        "        if not self._method_called:\n",
        "            self.i = 1\n",
        "            self.j = 0\n",
        "            self._method_called = True\n",
        "\n",
        "        if sampling == 0:\n",
        "            if GI_flag1 == 1:\n",
        "                self.i += 1\n",
        "                if self.i == 3:\n",
        "                    self.i = 0\n",
        "            sorted_indices = np.argsort(self.__distr)\n",
        "            selected_class = sorted_indices[-self.i]\n",
        "            selected_class_indices = np.where(self.__dataset[1] == selected_class)[0]\n",
        "            selected_feature_vectors = [self.__feature_vectors[index] for index in selected_class_indices]\n",
        "            self.under_sampling(selected_class, selected_feature_vectors)\n",
        "            return Client.cumulative_encrypted_distribution\n",
        "\n",
        "        if sampling == 1:\n",
        "            if GI_flag2 == 1:\n",
        "                self.j += 1\n",
        "            \"\"\"sorted_indices = np.argsort(self.__distr)\n",
        "            selected_class = sorted_indices[0]\n",
        "            multiple = int(1 / (4 * self.__imbalance))\"\"\"\n",
        "            self.over_sampling_from_folder_client()\n",
        "            return Client.cumulative_encrypted_distribution"
      ],
      "metadata": {
        "id": "BP0ugXMbagxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "server = Server()\n",
        "\n",
        "distr1 = [10, 500, 700, 4000]\n",
        "distr2 = [20, 700, 500, 3000]\n",
        "distr3 = [30, 400, 600, 3000]\n",
        "distr4 = [100, 50, 200, 10]\n",
        "\n",
        "\"\"\"distr1 = [10, 30, 700, 4000]\n",
        "distr2 = [20, 40, 500, 3000]\n",
        "distr3 = [30, 40, 600, 3000]\n",
        "distr4 = [50, 50, 200, 10]\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"distr1 = [10, 30, 3600, 4000]\n",
        "distr2 = [20, 40, 2700, 3000]\n",
        "distr3 = [30, 40, 2600, 3000]\n",
        "distr4 = [100, 50, 200, 10]\"\"\"\n",
        "\n",
        "\"\"\"distr1 = [2, 100, 600, 4000]\n",
        "distr2 = [3, 200, 700, 3000]\n",
        "distr3 = [5, 150, 800, 3000]\n",
        "distr4 = [30, 50, 20, 10]\"\"\"\n",
        "\n",
        "client_1 = Client(distr1,server,0)\n",
        "client_2 = Client(distr2, server, 1)\n",
        "client_3 = Client(distr3, server, 2)\n",
        "client_4 = Client(distr4, server, 3)"
      ],
      "metadata": {
        "id": "Qqi62JfuamTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "X = 0\n",
        "x_t, y_t, a = client_1.use_dataset()\n",
        "X+= len(y_t)\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, b = client_2.use_dataset()\n",
        "X+= len(y_t)\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, c = client_3.use_dataset()\n",
        "X+= len(y_t)\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, d = client_4.use_dataset()\n",
        "X+= len(y_t)\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)\n",
        "print(X)"
      ],
      "metadata": {
        "id": "XU5ENnQSawk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Function to update the client's local model\n",
        "def client_update(local_model, texts, labels):\n",
        "    # Train the local model on client data\n",
        "    local_model.fit(texts, labels, epochs=4 ,batch_size=64 ,verbose=0)  # Adjust epochs as needed\n",
        "    return local_model\n",
        "\n",
        "# Function to update the global model on the server\n",
        "def server_update(local_models):\n",
        "    local_weights = [model.get_weights() for model in local_models]\n",
        "    # Average the weights from all local models\n",
        "    averaged_weights = [np.mean(weights, axis=0) for weights in zip(*local_weights)]\n",
        "    # Update the global model with the averaged weights\n",
        "    updated_global_model = create_model_with_initial_weights()\n",
        "    updated_global_model.set_weights(averaged_weights)\n",
        "    return updated_global_model\n",
        "\n",
        "# Function to evaluate the global model\n",
        "def evaluate(global_model, texts, labels):\n",
        "    _, accuracy = global_model.evaluate(texts, labels, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[0])\n",
        "train_sequences0 = tokenizer.texts_to_sequences(x_train[0])\n",
        "train_padded0 = pad_sequences(train_sequences0, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[1])\n",
        "train_sequences1 = tokenizer.texts_to_sequences(x_train[1])\n",
        "train_padded1 = pad_sequences(train_sequences1, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[2])\n",
        "train_sequences2 = tokenizer.texts_to_sequences(x_train[2])\n",
        "train_padded2 = pad_sequences(train_sequences2, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[3])\n",
        "train_sequences3 = tokenizer.texts_to_sequences(x_train[3])\n",
        "train_padded3 = pad_sequences(train_sequences3, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "# Convert labels to TensorFlow format\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels = to_categorical(train_labels, num_classes=4)\n",
        "\n",
        "# Load the datasets\n",
        "x_train_A, y_train_A = train_padded0, y_train[0]\n",
        "x_train_B, y_train_B = train_padded1, y_train[1]\n",
        "x_train_C, y_train_C = train_padded2, y_train[2]\n",
        "x_train_D, y_train_D = train_padded3, y_train[3]\n",
        "x_test, y_test = test_padded, test_labels\n",
        "\n",
        "\n",
        "# Prepare labels (if necessary, depending on your label encoding)\n",
        "y_train_A = np.array(y_train_A)\n",
        "y_train_B = np.array(y_train_B)\n",
        "y_train_C = np.array(y_train_C)\n",
        "y_train_D = np.array(y_train_D)\n",
        "y_train_A = to_categorical(y_train_A, num_classes=4)\n",
        "y_train_B = to_categorical(y_train_B, num_classes=4)\n",
        "y_train_C = to_categorical(y_train_C, num_classes=4)\n",
        "y_train_D = to_categorical(y_train_D, num_classes=4)\n",
        "\n",
        "\n",
        "print(x_train_A.shape)\n",
        "print(y_train_A.shape)\n",
        "\n",
        "# Initialize the models for clients\n",
        "initial_model_A = create_model_with_initial_weights()  # Define your text model here\n",
        "initial_model_B = create_model_with_initial_weights()\n",
        "initial_model_C = create_model_with_initial_weights()\n",
        "initial_model_D = create_model_with_initial_weights()\n",
        "global_model = create_model_with_initial_weights()\n",
        "\n",
        "# Federated learning\n",
        "num_rounds = 20\n",
        "rounds = []\n",
        "accuracies = []\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    accuracy = evaluate(global_model, x_test, y_test)\n",
        "    print(f\"Round {round_num}: Accuracy = {accuracy * 100}\")\n",
        "\n",
        "    global_weights = global_model.get_weights()\n",
        "    initial_model_A.set_weights(global_weights)\n",
        "    initial_model_B.set_weights(global_weights)\n",
        "    initial_model_C.set_weights(global_weights)\n",
        "    initial_model_D.set_weights(global_weights)\n",
        "\n",
        "    initial_model_A = client_update(initial_model_A, x_train_A, y_train_A)\n",
        "    initial_model_B = client_update(initial_model_B, x_train_B, y_train_B)\n",
        "    initial_model_C = client_update(initial_model_C, x_train_C, y_train_C)\n",
        "    initial_model_D = client_update(initial_model_D, x_train_D, y_train_D)\n",
        "\n",
        "    # Aggregate model updates on the server\n",
        "    global_model = server_update([initial_model_A, initial_model_B, initial_model_C, initial_model_D])\n",
        "    rounds.append(round_num)\n",
        "    accuracies.append(accuracy * 100)\n",
        "\n",
        "# Final evaluation of the global model\n",
        "accuracy = evaluate(global_model,x_test ,y_test)\n",
        "print(f\"Round {round_num + 1}: Final Accuracy = {accuracy * 100}\")\n",
        "rounds.append(round_num+1)\n",
        "accuracies.append(accuracy * 100)\n",
        "# Generate classification report\n",
        "probabilities = global_model.predict(x_test)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "predicted_labels_onehot = to_categorical(predicted_labels)\n",
        "report = classification_report(y_test.argmax(axis=1), predicted_labels)\n",
        "print(report)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(rounds, accuracies, marker='o', label='Federated Model')\n",
        "plt.title(\"Round vs Accuracy\")\n",
        "plt.xlabel(\"Round Number\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "# Save accuracy and model\n",
        "np_accuracy = np.array(accuracies)\n",
        "np.savetxt('accuracy.txt', np_accuracy, fmt='%f', delimiter=',')\n",
        "global_model.save('text_model.keras')"
      ],
      "metadata": {
        "id": "yw6mGrqga6nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Assuming global_model is your trained Keras model and x_test and y_test are your test data\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_prob = global_model.predict(x_test)\n",
        "\n",
        "# Assuming y_test is one-hot encoded\n",
        "n_classes = y_test.shape[1]\n",
        "y_test_binary = y_test\n",
        "\n",
        "# Calculate ROC curve and AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure()\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']  # Adjust the number of colors based on the number of classes\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], color=colors[i % len(colors)], lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Multiclass')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print AUC for each class\n",
        "for i in range(n_classes):\n",
        "    print(f'AUC for class {i}: {roc_auc[i]}')"
      ],
      "metadata": {
        "id": "cH8gZPmnbLtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0], y_train[0], LD_0 = base_under_sampling(x_train[0], y_train[0], distr1)\n",
        "x_train[1], y_train[1], LD_1 = base_under_sampling(x_train[1], y_train[1], distr2)\n",
        "x_train[2], y_train[2], LD_2 = base_under_sampling(x_train[2], y_train[2], distr3)\n",
        "x_train[3], y_train[3], LD_3 = base_under_sampling(x_train[3], y_train[3], distr4)\n",
        "y = LD_0 + LD_1 + LD_2 + LD_3\n",
        "Y = np.sum(y)"
      ],
      "metadata": {
        "id": "MfjmjJwcbTko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LD_0)\n",
        "print(LD_1)\n",
        "print(LD_2)\n",
        "print(LD_3)\n",
        "print(Y)\n",
        "print()\n",
        "print(distr1)\n",
        "print(distr2)\n",
        "print(distr3)\n",
        "print(distr4)"
      ],
      "metadata": {
        "id": "J6uSh-I4bcNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Function to update the client's local model\n",
        "def client_update(local_model, texts, labels):\n",
        "    # Train the local model on client data\n",
        "    local_model.fit(texts, labels, epochs=4 ,batch_size=64 ,verbose=0)  # Adjust epochs as needed\n",
        "    return local_model\n",
        "\n",
        "# Function to update the global model on the server\n",
        "def server_update(local_models):\n",
        "    local_weights = [model.get_weights() for model in local_models]\n",
        "    # Average the weights from all local models\n",
        "    averaged_weights = [np.mean(weights, axis=0) for weights in zip(*local_weights)]\n",
        "    # Update the global model with the averaged weights\n",
        "    updated_global_model = create_model_with_initial_weights()\n",
        "    updated_global_model.set_weights(averaged_weights)\n",
        "    return updated_global_model\n",
        "\n",
        "# Function to evaluate the global model\n",
        "def evaluate(global_model, texts, labels):\n",
        "    _, accuracy = global_model.evaluate(texts, labels, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[0])\n",
        "train_sequences0 = tokenizer.texts_to_sequences(x_train[0])\n",
        "train_padded0 = pad_sequences(train_sequences0, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[1])\n",
        "train_sequences1 = tokenizer.texts_to_sequences(x_train[1])\n",
        "train_padded1 = pad_sequences(train_sequences1, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[2])\n",
        "train_sequences2 = tokenizer.texts_to_sequences(x_train[2])\n",
        "train_padded2 = pad_sequences(train_sequences2, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[3])\n",
        "train_sequences3 = tokenizer.texts_to_sequences(x_train[3])\n",
        "train_padded3 = pad_sequences(train_sequences3, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "# Convert labels to TensorFlow format\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels = to_categorical(train_labels, num_classes=4)\n",
        "\n",
        "# Load the datasets\n",
        "x_train_A, y_train_A = train_padded0, y_train[0]\n",
        "x_train_B, y_train_B = train_padded1, y_train[1]\n",
        "x_train_C, y_train_C = train_padded2, y_train[2]\n",
        "x_train_D, y_train_D = train_padded3, y_train[3]\n",
        "x_test, y_test = test_padded, test_labels\n",
        "\n",
        "\n",
        "# Prepare labels (if necessary, depending on your label encoding)\n",
        "y_train_A = np.array(y_train_A)\n",
        "y_train_B = np.array(y_train_B)\n",
        "y_train_C = np.array(y_train_C)\n",
        "y_train_D = np.array(y_train_D)\n",
        "y_train_A = to_categorical(y_train_A, num_classes=4)\n",
        "y_train_B = to_categorical(y_train_B, num_classes=4)\n",
        "y_train_C = to_categorical(y_train_C, num_classes=4)\n",
        "y_train_D = to_categorical(y_train_D, num_classes=4)\n",
        "\n",
        "\n",
        "print(x_train_A.shape)\n",
        "print(y_train_A.shape)\n",
        "\n",
        "# Initialize the models for clients\n",
        "initial_model_A = create_model_with_initial_weights()  # Define your text model here\n",
        "initial_model_B = create_model_with_initial_weights()\n",
        "initial_model_C = create_model_with_initial_weights()\n",
        "initial_model_D = create_model_with_initial_weights()\n",
        "global_model = create_model_with_initial_weights()\n",
        "\n",
        "# Federated learning\n",
        "num_rounds = 20\n",
        "rounds1 = []\n",
        "accuracies1 = []\n",
        "denom = Y/X\n",
        "for round_num in range(num_rounds):\n",
        "    accuracy = evaluate(global_model, x_test, y_test)\n",
        "    accuracy = accuracy/max(1,denom)\n",
        "    print(f\"Round {round_num}: Accuracy = {accuracy * 100}\")\n",
        "\n",
        "    global_weights = global_model.get_weights()\n",
        "    initial_model_A.set_weights(global_weights)\n",
        "    initial_model_B.set_weights(global_weights)\n",
        "    initial_model_C.set_weights(global_weights)\n",
        "    initial_model_D.set_weights(global_weights)\n",
        "\n",
        "    initial_model_A = client_update(initial_model_A, x_train_A, y_train_A)\n",
        "    initial_model_B = client_update(initial_model_B, x_train_B, y_train_B)\n",
        "    initial_model_C = client_update(initial_model_C, x_train_C, y_train_C)\n",
        "    initial_model_D = client_update(initial_model_D, x_train_D, y_train_D)\n",
        "\n",
        "    # Aggregate model updates on the server\n",
        "    global_model = server_update([initial_model_A, initial_model_B, initial_model_C, initial_model_D])\n",
        "    rounds1.append(round_num)\n",
        "    accuracies1.append(accuracy * 100)\n",
        "\n",
        "# Final evaluation of the global model\n",
        "accuracy = evaluate(global_model,x_test ,y_test)\n",
        "accuracy = accuracy/max(1,denom)\n",
        "print(f\"Round {round_num + 1}: Final Accuracy = {accuracy * 100}\")\n",
        "rounds1.append(round_num+1)\n",
        "accuracies1.append(accuracy * 100)\n",
        "\n",
        "# Generate classification report\n",
        "probabilities = global_model.predict(x_test)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "predicted_labels_onehot = to_categorical(predicted_labels)\n",
        "report = classification_report(y_test.argmax(axis=1), predicted_labels)\n",
        "print(report)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(rounds1, accuracies1, marker='o', label='Federated Model')\n",
        "plt.title(\"Round vs Accuracy\")\n",
        "plt.xlabel(\"Round Number\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "global_model.save('text_model_US.keras')"
      ],
      "metadata": {
        "id": "9679CPxKbiV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Assuming global_model is your trained Keras model and x_test and y_test are your test data\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_prob = global_model.predict(x_test)\n",
        "\n",
        "# Assuming y_test is one-hot encoded\n",
        "n_classes = y_test.shape[1]\n",
        "y_test_binary = y_test\n",
        "\n",
        "# Calculate ROC curve and AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure()\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']  # Adjust the number of colors based on the number of classes\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], color=colors[i % len(colors)], lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Multiclass')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print AUC for each class\n",
        "for i in range(n_classes):\n",
        "    print(f'AUC for class {i}: {roc_auc[i]}')"
      ],
      "metadata": {
        "id": "XuYFEeH7cQ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_t, y_t, a = client_1.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, b = client_2.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, c = client_3.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, d = client_4.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)"
      ],
      "metadata": {
        "id": "ks_Sw7ICcXjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0], y_train[0], LD_0 = over_sampling_from_folder_client(x_train[0], y_train[0], distr1)\n",
        "x_train[1], y_train[1], LD_1 = over_sampling_from_folder_client(x_train[1], y_train[1], distr2)\n",
        "x_train[2], y_train[2], LD_2 = over_sampling_from_folder_client(x_train[2], y_train[2], distr3)\n",
        "x_train[3], y_train[3], LD_3 = over_sampling_from_folder_client(x_train[3], y_train[3], distr4)\n",
        "y = LD_0 + LD_1 + LD_2 + LD_3\n",
        "Y = np.sum(y)"
      ],
      "metadata": {
        "id": "CCkpuQXycnVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LD_0)\n",
        "print(LD_1)\n",
        "print(LD_2)\n",
        "print(LD_3)\n",
        "print(Y)\n",
        "print()\n",
        "print(distr1)\n",
        "print(distr2)\n",
        "print(distr3)\n",
        "print(distr4)"
      ],
      "metadata": {
        "id": "w5QKPNe4cvUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update the client's local model\n",
        "def client_update(local_model, texts, labels):\n",
        "    # Train the local model on client data\n",
        "    local_model.fit(texts, labels, epochs=4 ,batch_size=64 ,verbose=0)  # Adjust epochs as needed\n",
        "    return local_model\n",
        "\n",
        "# Function to update the global model on the server\n",
        "def server_update(local_models):\n",
        "    local_weights = [model.get_weights() for model in local_models]\n",
        "    # Average the weights from all local models\n",
        "    averaged_weights = [np.mean(weights, axis=0) for weights in zip(*local_weights)]\n",
        "    # Update the global model with the averaged weights\n",
        "    updated_global_model = create_model_with_initial_weights()\n",
        "    updated_global_model.set_weights(averaged_weights)\n",
        "    return updated_global_model\n",
        "\n",
        "# Function to evaluate the global model\n",
        "def evaluate(global_model, texts, labels):\n",
        "    _, accuracy = global_model.evaluate(texts, labels, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[0])\n",
        "train_sequences0 = tokenizer.texts_to_sequences(x_train[0])\n",
        "train_padded0 = pad_sequences(train_sequences0, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[1])\n",
        "train_sequences1 = tokenizer.texts_to_sequences(x_train[1])\n",
        "train_padded1 = pad_sequences(train_sequences1, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[2])\n",
        "train_sequences2 = tokenizer.texts_to_sequences(x_train[2])\n",
        "train_padded2 = pad_sequences(train_sequences2, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[3])\n",
        "train_sequences3 = tokenizer.texts_to_sequences(x_train[3])\n",
        "train_padded3 = pad_sequences(train_sequences3, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "# Convert labels to TensorFlow format\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels = to_categorical(train_labels, num_classes=4)\n",
        "\n",
        "# Load the datasets\n",
        "x_train_A, y_train_A = train_padded0, y_train[0]\n",
        "x_train_B, y_train_B = train_padded1, y_train[1]\n",
        "x_train_C, y_train_C = train_padded2, y_train[2]\n",
        "x_train_D, y_train_D = train_padded3, y_train[3]\n",
        "x_test, y_test = test_padded, test_labels\n",
        "\n",
        "\n",
        "# Prepare labels (if necessary, depending on your label encoding)\n",
        "y_train_A = np.array(y_train_A)\n",
        "y_train_B = np.array(y_train_B)\n",
        "y_train_C = np.array(y_train_C)\n",
        "y_train_D = np.array(y_train_D)\n",
        "y_train_A = to_categorical(y_train_A, num_classes=4)\n",
        "y_train_B = to_categorical(y_train_B, num_classes=4)\n",
        "y_train_C = to_categorical(y_train_C, num_classes=4)\n",
        "y_train_D = to_categorical(y_train_D, num_classes=4)\n",
        "\n",
        "\n",
        "# Initialize the models for clients\n",
        "initial_model_A = create_model_with_initial_weights()  # Define your text model here\n",
        "initial_model_B = create_model_with_initial_weights()\n",
        "initial_model_C = create_model_with_initial_weights()\n",
        "initial_model_D = create_model_with_initial_weights()\n",
        "global_model = create_model_with_initial_weights()\n",
        "\n",
        "# Federated learning\n",
        "num_rounds = 20\n",
        "rounds2 = []\n",
        "accuracies2 = []\n",
        "denom = Y/X\n",
        "print(denom)\n",
        "for round_num in range(num_rounds):\n",
        "    accuracy = evaluate(global_model, x_test, y_test)\n",
        "    accuracy = accuracy/max(1,denom)\n",
        "    print(f\"Round {round_num}: Accuracy = {accuracy * 100}\")\n",
        "    global_weights = global_model.get_weights()\n",
        "    initial_model_A.set_weights(global_weights)\n",
        "    initial_model_B.set_weights(global_weights)\n",
        "    initial_model_C.set_weights(global_weights)\n",
        "    initial_model_D.set_weights(global_weights)\n",
        "\n",
        "    initial_model_A = client_update(initial_model_A, x_train_A, y_train_A)\n",
        "    initial_model_B = client_update(initial_model_B, x_train_B, y_train_B)\n",
        "    initial_model_C = client_update(initial_model_C, x_train_C, y_train_C)\n",
        "    initial_model_D = client_update(initial_model_D, x_train_D, y_train_D)\n",
        "\n",
        "    # Aggregate model updates on the server\n",
        "    global_model = server_update([initial_model_A, initial_model_B, initial_model_C, initial_model_D])\n",
        "    rounds2.append(round_num)\n",
        "    accuracies2.append(accuracy * 100)\n",
        "\n",
        "# Final evaluation of the global model\n",
        "accuracy = evaluate(global_model,x_test ,y_test)\n",
        "accuracy = accuracy/max(1,denom)\n",
        "print(f\"Round {round_num + 1}: Final Accuracy = {accuracy * 100}\")\n",
        "rounds2.append(round_num+1)\n",
        "accuracies2.append(accuracy * 100)\n",
        "# Generate classification report\n",
        "probabilities = global_model.predict(x_test)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "predicted_labels_onehot = to_categorical(predicted_labels)\n",
        "report = classification_report(y_test.argmax(axis=1), predicted_labels)\n",
        "print(report)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(rounds2, accuracies2, marker='o', label='Federated Model')\n",
        "plt.title(\"Round vs Accuracy\")\n",
        "plt.xlabel(\"Round Number\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "global_model.save('text_model_OS.keras')"
      ],
      "metadata": {
        "id": "1dd8ZSzCcztV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities\n",
        "y_pred_prob = global_model.predict(x_test)\n",
        "\n",
        "# Assuming y_test is one-hot encoded\n",
        "n_classes = y_test.shape[1]\n",
        "y_test_binary = y_test\n",
        "\n",
        "# Calculate ROC curve and AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure()\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']  # Adjust the number of colors based on the number of classes\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], color=colors[i % len(colors)], lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Multiclass')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print AUC for each class\n",
        "for i in range(n_classes):\n",
        "    print(f'AUC for class {i}: {roc_auc[i]}')"
      ],
      "metadata": {
        "id": "gLrSSIKsdEJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_t, y_t, a = client_1.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, b = client_2.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, c = client_3.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, d = client_4.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "y = a + b + c + d\n",
        "Y = np.sum(y)\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "UCCjZ1gJdJy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server.balance_check()"
      ],
      "metadata": {
        "id": "hHARufXUdRge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_t, y_t, a = client_1.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, b = client_2.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, c = client_3.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "x_t, y_t, d = client_4.use_dataset()\n",
        "x_train.append(x_t)\n",
        "y_train.append(y_t)\n",
        "y = a + b + c + d\n",
        "Y = np.sum(y)\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQQ0jH2zdxJW",
        "outputId": "c524b2ed-d28b-403a-ed92-5e94c7e7d394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: 5382 5382\n",
            "Feature vector: (5382, 4)\n",
            "Dataset Shape: 4185 4185\n",
            "Feature vector: (4185, 4)\n",
            "Dataset Shape: 3777 3777\n",
            "Feature vector: (3777, 4)\n",
            "Dataset Shape: 360 360\n",
            "Feature vector: (360, 4)\n",
            "[ 389  500  700 3793]\n",
            "[ 161  700  500 2824]\n",
            "[ 144  400  600 2633]\n",
            "[100, 50, 200, 10]\n",
            "13704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update the client's local model\n",
        "def client_update(local_model, texts, labels):\n",
        "    # Train the local model on client data\n",
        "    local_model.fit(texts, labels, epochs=4 ,batch_size=64 ,verbose=0)  # Adjust epochs as needed\n",
        "    return local_model\n",
        "\n",
        "# Function to update the global model on the server\n",
        "def server_update(local_models):\n",
        "    local_weights = [model.get_weights() for model in local_models]\n",
        "    # Average the weights from all local models\n",
        "    averaged_weights = [np.mean(weights, axis=0) for weights in zip(*local_weights)]\n",
        "    # Update the global model with the averaged weights\n",
        "    updated_global_model = create_model_with_initial_weights()\n",
        "    updated_global_model.set_weights(averaged_weights)\n",
        "    return updated_global_model\n",
        "\n",
        "# Function to evaluate the global model\n",
        "def evaluate(global_model, texts, labels):\n",
        "    _, accuracy = global_model.evaluate(texts, labels, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[0])\n",
        "train_sequences0 = tokenizer.texts_to_sequences(x_train[0])\n",
        "train_padded0 = pad_sequences(train_sequences0, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[1])\n",
        "train_sequences1 = tokenizer.texts_to_sequences(x_train[1])\n",
        "train_padded1 = pad_sequences(train_sequences1, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[2])\n",
        "train_sequences2 = tokenizer.texts_to_sequences(x_train[2])\n",
        "train_padded2 = pad_sequences(train_sequences2, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "#tokenizer.fit_on_texts(x_train[3])\n",
        "train_sequences3 = tokenizer.texts_to_sequences(x_train[3])\n",
        "train_padded3 = pad_sequences(train_sequences3, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "# Convert labels to TensorFlow format\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels = to_categorical(train_labels, num_classes=4)\n",
        "\n",
        "# Load the datasets\n",
        "x_train_A, y_train_A = train_padded0, y_train[0]\n",
        "x_train_B, y_train_B = train_padded1, y_train[1]\n",
        "x_train_C, y_train_C = train_padded2, y_train[2]\n",
        "x_train_D, y_train_D = train_padded3, y_train[3]\n",
        "x_test, y_test = test_padded, test_labels\n",
        "\n",
        "\n",
        "# Prepare labels (if necessary, depending on your label encoding)\n",
        "y_train_A = np.array(y_train_A)\n",
        "y_train_B = np.array(y_train_B)\n",
        "y_train_C = np.array(y_train_C)\n",
        "y_train_D = np.array(y_train_D)\n",
        "y_train_A = to_categorical(y_train_A, num_classes=4)\n",
        "y_train_B = to_categorical(y_train_B, num_classes=4)\n",
        "y_train_C = to_categorical(y_train_C, num_classes=4)\n",
        "y_train_D = to_categorical(y_train_D, num_classes=4)\n",
        "\n",
        "\n",
        "# Initialize the models for clients\n",
        "initial_model_A = create_model_with_initial_weights()  # Define your text model here\n",
        "initial_model_B = create_model_with_initial_weights()\n",
        "initial_model_C = create_model_with_initial_weights()\n",
        "initial_model_D = create_model_with_initial_weights()\n",
        "global_model = create_model_with_initial_weights()\n",
        "\n",
        "# Federated learning\n",
        "num_rounds = 20\n",
        "rounds3 = []\n",
        "accuracies3 = []\n",
        "denom = Y/X\n",
        "for round_num in range(num_rounds):\n",
        "    accuracy = evaluate(global_model, x_test, y_test)\n",
        "    accuracy = accuracy/max(1,denom)\n",
        "    print(f\"Round {round_num}: Accuracy = {accuracy * 100}\")\n",
        "\n",
        "    global_weights = global_model.get_weights()\n",
        "    initial_model_A.set_weights(global_weights)\n",
        "    initial_model_B.set_weights(global_weights)\n",
        "    initial_model_C.set_weights(global_weights)\n",
        "    initial_model_D.set_weights(global_weights)\n",
        "\n",
        "    initial_model_A = client_update(initial_model_A, x_train_A, y_train_A)\n",
        "    initial_model_B = client_update(initial_model_B, x_train_B, y_train_B)\n",
        "    initial_model_C = client_update(initial_model_C, x_train_C, y_train_C)\n",
        "    initial_model_D = client_update(initial_model_D, x_train_D, y_train_D)\n",
        "\n",
        "    # Aggregate model updates on the server\n",
        "    global_model = server_update([initial_model_A, initial_model_B, initial_model_C, initial_model_D])\n",
        "    rounds3.append(round_num)\n",
        "    accuracies3.append(accuracy * 100)\n",
        "\n",
        "# Final evaluation of the global model\n",
        "accuracy = evaluate(global_model,x_test ,y_test)\n",
        "accuracy = accuracy/max(1,denom)\n",
        "print(f\"Round {round_num + 1}: Final Accuracy = {accuracy * 100}\")\n",
        "rounds3.append(round_num+1)\n",
        "accuracies3.append(accuracy * 100)\n",
        "# Generate classification report\n",
        "probabilities = global_model.predict(x_test)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "predicted_labels_onehot = to_categorical(predicted_labels)\n",
        "report = classification_report(y_test.argmax(axis=1), predicted_labels)\n",
        "print(report)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(rounds3, accuracies3, marker='o', label='Federated Model')\n",
        "plt.title(\"Round vs Accuracy\")\n",
        "plt.xlabel(\"Round Number\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "global_model.save('text_FLICKER.keras')"
      ],
      "metadata": {
        "id": "9VN4vtw5d3PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities\n",
        "y_pred_prob = global_model.predict(x_test)\n",
        "\n",
        "# Assuming y_test is one-hot encoded\n",
        "n_classes = y_test.shape[1]\n",
        "y_test_binary = y_test\n",
        "\n",
        "# Calculate ROC curve and AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure()\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']  # Adjust the number of colors based on the number of classes\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], color=colors[i % len(colors)], lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Multiclass')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print AUC for each class\n",
        "for i in range(n_classes):\n",
        "    print(f'AUC for class {i}: {roc_auc[i]}')"
      ],
      "metadata": {
        "id": "E4QGBkOYezMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(rounds, accuracies, marker='o', markersize=8, linewidth=1, label='Training with Class Imbalance')\n",
        "plt.plot(rounds1, accuracies1, marker='h', markersize=8, linewidth=1, label='Under Sampling')\n",
        "plt.plot(rounds2, accuracies2, marker='s', markersize=8, linewidth=1, label='Over Sampling')\n",
        "plt.plot(rounds3, accuracies3, marker='>', markersize=8, linewidth=1, label='FLICKER')\n",
        "\n",
        "plt.title(\"Round vs Accuracy\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Round Number\", fontsize=14, fontweight='bold')\n",
        "plt.ylabel(\"Normalized Accuracy (%)\", fontsize=14, fontweight='bold')\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=14)  # Add a legend to differentiate the lines\n",
        "plt.ylim(20, 90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MaFwM-wRe244"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}